import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
from opacus import PrivacyEngine  # 用于DP-SGD

### 生成器和判别器的网络结构
class Generator(nn.Module):
    def __init__(self, latent_dim=100):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Linear(256, 784),  # MNIST 图片 28x28=784
            nn.Tanh()
        )

    def forward(self, z):
        return self.model(z)

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(784, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.model(x)
    

### 加载MNIST数据集
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Lambda(lambda x: x.view(-1))
])

train_loader = torch.utils.data.DataLoader(
    torchvision.datasets.MNIST(root="./data", train=True, download=True, transform=transform),
    batch_size=64,
    shuffle=True
)
### 初始模型和优化器
generator = Generator()
discriminator = Discriminator()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
generator.to(device)
discriminator.to(device)

optimizer_G = optim.Adam(generator.parameters(), lr=1e-3)
optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-3)

###为判别器添加差分隐私
from opacus.accountants.utils import get_noise_multiplier

# 计算噪声强度，确保 (ε=3, δ=1e-5) 级别隐私
target_epsilon = 3.0
delta = 1e-5
sample_rate = 64 / len(train_loader.dataset)
noise_multiplier = get_noise_multiplier(target_epsilon, delta, sample_rate, epochs=10)

# 应用 DP-SGD
privacy_engine = PrivacyEngine()
discriminator, optimizer_D, train_loader = privacy_engine.make_private_with_epsilon(
    module=discriminator,
    optimizer=optimizer_D,
    data_loader=train_loader,
    target_epsilon=target_epsilon,
    target_delta=delta,
    epochs=10,
    max_grad_norm=1.0,  # Adaptive Clipping 可以动态调整
)

### 训练GAN模型
criterion = nn.BCELoss()  # 交叉熵损失
latent_dim = 100
num_epochs = 10

for epoch in range(num_epochs):
    for i, (real_images, _) in enumerate(train_loader):
        real_images = real_images.to(device)

        # 训练判别器
        optimizer_D.zero_grad()

        # 真实数据
        real_labels = torch.ones((real_images.size(0), 1)).to(device)
        real_loss = criterion(discriminator(real_images), real_labels)

        # 生成数据
        z = torch.randn(real_images.size(0), latent_dim).to(device)
        fake_images = generator(z)
        fake_labels = torch.zeros((real_images.size(0), 1)).to(device)
        fake_loss = criterion(discriminator(fake_images.detach()), fake_labels)

        # 总损失
        loss_D = real_loss + fake_loss
        loss_D.backward()
        optimizer_D.step()

        # 训练生成器
        optimizer_G.zero_grad()
        fake_labels = torch.ones((real_images.size(0), 1)).to(device)  # 让判别器误判
        loss_G = criterion(discriminator(fake_images), fake_labels)
        loss_G.backward()
        optimizer_G.step()

    # 记录隐私预算
    epsilon = privacy_engine.get_epsilon(delta)

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss_D: {loss_D.item():.4f}, Loss_G: {loss_G.item():.4f}, ε={epsilon:.2f}")

### 生成图片样本
def generate_images(generator, latent_dim=100):
    z = torch.randn(16, latent_dim).to(device)
    fake_images = generator(z).cpu().detach().numpy()
    fake_images = fake_images.reshape(-1, 28, 28)

    fig, axes = plt.subplots(4, 4, figsize=(5, 5))
    for i, ax in enumerate(axes.flat):
        ax.imshow(fake_images[i], cmap="gray")
        ax.axis("off")
    plt.show()

generate_images(generator)
